<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-06-14T22:46:20-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">AI and Machine Learning Blog</title><subtitle>All about AI and Machine Learning..</subtitle><author><name>Mohammed Alhamid</name></author><entry><title type="html">مقدمة في ترميز النصوص</title><link href="http://localhost:4000/into_text_encoding/" rel="alternate" type="text/html" title="&lt;div class=&quot;col-md-6 text-right&quot;&gt;مقدمة في ترميز النصوص&lt;/div&gt;" /><published>2020-06-11T00:00:00-04:00</published><updated>2020-06-11T00:00:00-04:00</updated><id>http://localhost:4000/text-encoding</id><content type="html" xml:base="http://localhost:4000/into_text_encoding/">&lt;p&gt;&lt;img src=&quot;/assets/images/126-icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
كما هو من البديهي، فإن الآلة لا تتعامل مع النصوص بحروفها وأفعالها وأسمائها وأنه يتوجب علينا تحويل هذه النصوص لمعاملات رقمية يمكن للآلة أن تبني خوارزمياتها عليها. بناءً على ذلك، كيف للآلة أن تتعلم أن نصاً معيناً يحمل صفةً إيجابية مثلاً أو سلبية؟ كيف لمحركات البحث أن تفهم عن ماذا نبحث عند ادخالنا لمجموعة من النصوص في حقل الادخال. كل ذلك مبني على مفهوم بسيط يطلق عليه الترميز. 
&lt;br /&gt;&lt;br /&gt;
تعلم الآلة دائماً ما يبتدئ ببناء قناة تتدفق منها البيانات عبر مراحل حتى الوصول من خلالها لبناء النموذج. هذه البيانات تحتاج منا لتحويل هذه النصوص لمعاملات رقمية. عملية الترميز هذه تمكننا من بناء نماذج لتعلم الآلة بنفس الآلية لمثيلات هذه البيانات من البيانات الرقمية الأصيلة كمجموع المبيعات وعدد القطع والأوزان وغيرها. تعرف عملية الترميز بمصطلح &quot;Text Encoding&quot;.
&lt;br /&gt;&lt;br /&gt;
التقنيات المستخدمة اليوم لترميز النصوص ليست بالمعقدة إطلاقاً وسنستعرض سوية مجموعة منها مع الأمثلة باستخدام لغة بايثون، بالتفصيل. سنستخدم في هذا الشرح مجموعة من النصوص استخرجت من موسوعة ويكيبيديا تتكلم عن عدد الأشجار الموجودة حول العالم.
&lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;corpus = [
	&quot;The number of trees in the world, according to a 2015 estimate, is 3.04 trillion.&quot;,
	&quot;46% of the trees in the world are in the tropics or sub-tropics.&quot;,
	&quot;20% of the trees in the world are in the temperate zones.&quot;,
	&quot;24% of threes in the world are in the coniferous boreal forests.&quot;,
	&quot;There about 15 billion trees are cut down annually.&quot;,
	&quot;There about 5 billion trees are planted annually.&quot;,
]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
&lt;h2&gt;استخراج المميزات من النصوص&lt;/h2&gt;
نماذج تعلم الآلة تتعلم من المميزات الوصول لأهداف التعلم. هذه المميزات يطلق عليها (Features) هي خلاصة تنقيحنا للبيانات واستخراج ما نظن أنه مفيد لتعلم الآلة. هذا في حال كان التعلم عن طريق الاشراف حيث نزود النموذج ببيانات التدريب والعناصر المستهدفة، كما أن التعلم الغير اشرافي يستخدم أيضاً لترميز النصوص.
&lt;br /&gt;&lt;br /&gt;
استخراج المميزات يمر بأربع مراحل أساسية بالإمكان الاستزادة عليها حسب سياق المشكلة ونوع الهدف المراد للآلة أن تستهدفه. الخطوة الأولى تهدف لاستخلاص الكلمات من خلال فصلها عن الجمل. تلي هذه الخطوة إزالة المستبعدات وهي تلك الكلمات التي نستبعدها من سلسلة الكلمات المستخلصة ليسهل علينا معالجة اللغة. يمكننا تحديد هذه المستبعدات عن طريق الانتباه لكثرة تكرارها كحروف الجر (مثلاً: في، على، من، إلى) وحروف العطف والاستفهام والشرط. لا يوجد تعريف واضح لهذه المستبعدات ولا قائمة بالكلمات التي تشملها سواءً باللغة الإنجليزية أو العربية لعدم وجود توافق علمي شامل عما يمكننا استبعاده. على الرغم من ذلك فهناك مكتبات توفر قائمتها من هذه المستبعدات يمكن استخدامها بسهولة. ولتبسيط المفهوم، فيمكننا اعتبار الكلمات المستبعدة هي كل تلك الكلمات التي لا تحمل معنى بصفتها الفردية و التي تحتاج لوضعها في سياق أو مضافة لكلمات أخرى. أول من اقترح إزالة هذه الكلمات هو العالم (Hans Peter Luhn) في عام ١٩٥٩ م. 
&lt;br /&gt;&lt;br /&gt;
بعد استخلاص الكلمات من النصوص نحتاج لاستعادة جذورها حتى تصل كل كلمة إلى جذرها. بالنسبة للغات التي تُشكل في أشكال حروف كبيرة وأخرى صغيرة كاللغة الإنجليزية، فيتوجب علينا استخدام نمط واحد لشكل هذه الحروف، أي تحويل جميع الحروف لحروف صغيرة، مثلاً. أما بالنسبة للغة العربية فيتوجب علينا الانتباه لتصحيح الكلمات التي تكتب خطأً بالهاء أو التاء المربوطة مثل: &quot;مكتبة&quot; لتصحيح &quot;مكتبه&quot;، وهكذا. الخطوة الرابعة هي إزالة علامات الترقيم والأحرف الخاصة والكلمات التي يبلغ طولها حرفاً واحداً. 
&lt;br /&gt;&lt;br /&gt;

&lt;h3&gt; استخراج الكلمات &lt;/h3&gt;

يمكن استخراج الكلمات باستخدام الأكواد المذيلة بالأسفل مع العلم أن مكتبة (Keras) تقدم واجهات (API) تقوم بهذه 
العملية.
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Extracting the tokens using NLTK
# We need to serialize the text to splits the works into tokens
nltk_tokens = [] 
for text in corpus:
    pre_text = pd.Series(text).str.cat(sep=' ')
    nltk_tokens.append(word_tokenize(pre_text))
print(nltk_tokens)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
وهنا باستخدام المكتبة: 
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Extracting the tokens using Keras
ks_tokens = []
for text in corpus: 
    ks_tokens.append(keras_text_to_word_sequence(text))
print(ks_tokens)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
لو أخذنا أول جملة في النص الذي اخترناه من موسوعة ويكيبيديا، فإن مخرجات هذ الخطوة عبارة عن متجه يحتوي على الكلمات المكونة للجملة الأولى كما في الشرح التالي:

&lt;img src=&quot;/assets/images/127-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
&lt;h3&gt; تهيئة الكلمات المستخرجة &lt;/h3&gt;
تهيئة الكلمات تشمل الخطوات التي ذكرناها سابقاً والتي تشمل إزالة المستبعدات و استعادة جذور الكلمات و إزالة علامات الترقيم و الأحرف الخاصة و الرموز المكونة من حرف واحد. 
بالامكان تحميل الكلمات المستبعدة في اللغة الانجليزية من المكتبة الأكثر شيوعاً في معالجة اللغة الطبيعية (nltk) على النحو التالي:
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from nltk.corpus import stopwords
# Retriving the stop words from the library 
stop_words = set(stopwords.words('english'))

for i in range(0, len(ks_tokens)): 
    ks_tokens[i] = [w for w in pd.Series(ks_tokens[i]) if not w in stop_words]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
من أمثلة الكلمات المستبعدة، الكلمات التالية: ['on', 'other', 'of', 'him', 'didn', 'have', 'haven', 'or', 'won', 'couldn']. نتاج هذه الخطوة على متجه الكلمات للجملة الأولى توضحه الصورة التالية:
&lt;img src=&quot;/assets/images/128-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
يتطلب علينا الآن استعادة جذور الكلمات و سننفذ هذه الخطوة على النصوص الانجليزية باستخدام خوارزمية (Porter) على النحو التالي: 
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# We will use Porter algorithm to reduce the words. Porter has 5 phases of word reductions: 
from nltk.stem.porter import PorterStemmer
porter = PorterStemmer()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
لن نفصل في طريقة عمل هذه الخوارزمية، لكن لو أخذنا مثال كلمة (Eating) فإن الخورازمية تعمل على ازالة اللواحق لأصل الكلمة و تردها للجذر (Eat).
علينا الآن المرور على الكلمات المستخرجة و استعادة جذورها: 
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for tokens in ks_tokens:
    for i in range(0, len(tokens)):    
        tokens[i] = porter.stem(tokens[i])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;

أصبح المتجه المستخلص من الجملة الأولى من النص بهذا الشكل: 
&lt;img src=&quot;/assets/images/129-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
الأكواد التالية ستعمل على إزالة الأرقام و علامات الترقيم و الأحرف الخاصة كما تقدم: 
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for i in range(0, len(ks_tokens)):
    new_ks_tokens = []
    for tok in ks_tokens[i]: 
        tok = tok.translate(str.maketrans('', '', string.punctuation))
        if tok != &quot;&quot; and len(tok) &amp;gt; 1 and (tok.isnumeric()==False):
            new_ks_tokens.append(tok)
    ks_tokens[i] = new_ks_tokens
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
&lt;br /&gt;
وهكذا يصبح شكل المتجه النهائي بعد تهيئة هذه النصوص على هذا النحو: 
&lt;img src=&quot;/assets/images/130-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;h2&gt;ترميز النصوص&lt;/h2&gt;

تحتوي الخطوات السابقة على العديد من الحلقات المتكررة ويمكن بسهولة أن تكون مكلفة للغاية خصوصاً إذا زاد عدد الكلمات بشكل كبير. وبالتالي ، سوف نكرر الخطوات السابقة باستخدام أسطر قليلة من التعليمات البرمجية باستخدام مكتبة (Keras):
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.preprocessing.text import Tokenizer
# First step is to get an instance of the tokenizer class
tok = Tokenizer()
# Keras can fit our corpus in a single call
tok.fit_on_texts(corpus)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
بالامكان الآن استطلاع تردد كل كلمة في المتجهات و عدد تكرارها في كل جملة على النحو التالي: 
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Let's explore what is the content of the tokenized corpus
print('The frequency of each word in the corpus:')
print(tok.word_counts)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/131-icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
نستطلع فيما تبقى من هذه المقالة، طرق الترميز لمتجهات الكلمات بعد تنقيحها و معالجتها.
&lt;h3&gt;الترميز الساخن &lt;/h3&gt;
يقصد بالترميز الساخن بناء متجهات تحمل جميع المفردات الموجودة في القاموس النصي المدخل ويكون حجم المتجه مساو لعدد الكلمات المستخرجة. يحتوي عناصر كل متجه على قيم تساوي الصفر أو الواحد. عدد المتجهات يساوي عدد الجمل النصية المدخلة. سمي بالساخن نظراً أنه يشغل العناصر التي تظهر في الجملة بقيمة ١ عند ظهور الكلمة كما في المثال التالي:
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(tok.texts_to_matrix(corpus, mode='binary'))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/132-icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
الصورة التالية توضح ترميز الجملة الأولى على حسب ظهور الكلمات في القاموس. 
&lt;img src=&quot;/assets/images/133-icon.png&quot; alt=&quot;&quot; /&gt;
يرجى التنبه أن طريقة الترميز هذه افقدتنا ترتيب الكلمات، فنستطيع أن نتعلم من المتجه وجود الكلمة من عدمها لكن دون ترتيب الظهور.
&lt;h3&gt; الترميز العددي &lt;/h3&gt;
هذا النوع من الترميز مشابه لسابقه إلا أنه عوضاً عن استخدام القيمة ١، نستخدم تردد الكلمة في نفس الجملة.
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Encoding the frequency of each word in the sentence
print(tok.texts_to_matrix(corpus, mode='count'))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/134-icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
يستخدم لوصف هذا النوع من الترميز مصطلح ([Frequency-based vectorization) وهناك طرق مشابهة للترميز العددي أو الترددي أشهرها (TF‪-‬IDF). ويمكن حساب الترميز بهذه الطريقة بناء على عدد الظهور لكلمة معينة على اجمالي عدد الكلمات في المستند. 
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Encoding the frequency of each word in the sentence (TFIDF)
print(tok.texts_to_matrix(corpus, mode='tfidf'))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
&lt;h3&gt; استخدام نموذج لتضمين الكلمات &lt;/h3&gt;
في هذه النوع من الترميز، نعول على تعلم الآلة في بناء نموذج لحساب دلالة الكلمة بدلاً من ترميز ظهورها في الجملة. هذه الطريقة تعرف بمصطلح (Word Embedding). يتم بناء متجهات للكلمات بناءً على المسافة بين كل متجه وآخر. لبناء هذا النموذج، نستخدم شبكة عصبية لتتعلم ربط هذه المتجهات لبناء دلالة ضمنية تتنبأ بالكلمات المحيطة بها.
&lt;br /&gt;&lt;br /&gt;
تكرر للتو في الفقرة السابقة كلمة دلالة في أكثر من موضع، فما الدلالة التي نبحث عنها؟ الدلالة المقصودة هنا هي كيف لنا أن نعرف أن كلمتين مختلفتين في الحروف تتشابهان في المعنى؟ كلمة &quot;تعلم&quot;و كلمة &quot;دراسة&quot; كلاهما يحملان نفس الدلالة لكن كل كلمة منهما لا تشتركان في الحروف و لا في الأطوال. دلالة المعنى في اللغة الطبيعية تأتي في كيفية استخدام الكلمات في السياق وكيف تستخدم الكلمة مع نضيراتها في نفس الجملة. سنتطرق لكيفية بناء هذه النماذج التي تتنبأ بضمنية الكلمة ثم نستخدم بعض النماذج المدربة مسبقاً.
&lt;br /&gt;&lt;br /&gt;
يوجد نموذجان واسعا الانتشار الأول Word2Vec و الآخر GloVe. لبناء نموذج محاكي لطريقة بناء متجهات Word2Vec نحتاج المكتبات التالية للتسهيل:
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Building&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2vec&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typically&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;very&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;expensive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;so&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;we&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;need&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mind&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;approach&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cores&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiprocessing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Parameters&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dimensionality&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Maximum&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;between&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;within&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_count&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ignores&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;than&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Use&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;these&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;many&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threads&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;faster&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; 	&lt;span class=&quot;n&quot;&gt;multicore&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;machines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ks_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
الرسم التفاعلي التالي يرسم بشكل مقتطع طريقة بناء هذا النموذج حيث تُبنى شبكة عصبية من طبقة مخفية واحدة. هذا النموذج يُمكننا بسهولة مقارنة المفردات عن طريق تعلم التفاعل الضمني المتوفر من خلال النص المدخل. 
&lt;img src=&quot;/assets/images/138-icon.gif&quot; alt=&quot;&quot; /&gt;
بناء النموذج على عدد قليل من الكلمات ليس ذو قيمة، وذلك نظراً لعدم كفاية النصوص التي تمكن النموذج من تنبؤ المسافات بين كل متجه كما توضحه الصورة التالية. كما أن تكلفة بناء نماذج Word2Vec مرتفعة حيث تستغرق مساحة من الوقت و الذاكرة العشوائية عند البناء. وفي كثير من الأحيان، نلحظ أن بناء نموذج Word2Vec على قاعدة بيانات صغيرة سرعان ما ينتج عنه نموذجاً يكون مضاعفاً لحجم البيانات الأساسي. وعليه بالامكان استخدام نماذج تم تدريبها مسبقاً على بيانات أصغر بالحجم و حققت دقة عالية في بناء المتجهات الضمنية للكلمات. 
&lt;img src=&quot;/assets/images/137-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
سنستخدم نموذج GloVe وهي خوارزمية تم تدريبها على نصوص من موسوعة وكيبيديا و متوفرة من جامعة ستانفورد على هذا &lt;a href=&quot;https://nlp.stanford.edu/data/glove.6B.zip&quot;&gt; الرابط &lt;/a&gt;. الأكواد التالية ستعمل على تحميل النموذج واستخدامه.
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np
from scipy import spatial

embeddings_dict = {}
with open(&quot;models/glove.6B.50d.txt&quot;, &quot;r&quot;) as file:
    for line in file: 
        values = line.split()
        word = values[0]
        vector = np.asarray(values[1:], &quot;float32&quot;)
        embeddings_dict[word] = vector
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
لو سألنا النموذج ماهي الكلمات القريبة من الكلمة (‪'‬book‪'‬) فستكون الاجابة مقاربة للتالي: 
['book',
 'books',
 'story',
 'biography',
 'novel',
 'writing',
 'wrote',
 'author',
 'titled',
 'published']‫.‬
الصورة التالية توضح المتجهات المتقاربة لحد ١٠٠ كلمة لكل متجه.
&lt;img src=&quot;/assets/images/135-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
الرسم البياني في الصورة السابقة مبني على حساب فرق المسافة بين المتجهات. هناك عمليات رياضية مختلفة تُستخدم لحساب العلاقة بين المتجهات. الأكواد التالية تحسب العلاقة بين المتجهات باستخدام (Euclidean) أو (Cosine Similarity).
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Example 1 
x = embeddings_dict['book']
y = embeddings_dict['notebook']
math.sqrt(sum([(a - b) ** 2 for a, b in zip(x, y)]))
---
5.506975291916892
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div&gt;
&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Example 2
x = embeddings_dict['book']
y = embeddings_dict['notebook']
spatial.distance.cosine(x,y)
---
0.6004519462585449 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
&lt;h2&gt; تحديات حول ترميز النصوص &lt;/h2&gt;
&lt;h4&gt; الحفاظ على الترتيب &lt;/h4&gt;
الترميز باستخدام المتجهات يستند على فهرس الكلمات الموجودة في القاموس وكما تطرقنا في المثال بداية المقال أن الترتيب في الترميز الساخن يفقدنا الحفاظ على ترتيب الكلمات في الجملة.  هناك حلول مكلفة لحل هذه المشكلة عن طريق بناء متجهات تعبر عن الجملة الواحدة بدلاً من متجه واحد لكل جملة. اختيار الترميز المناسب في هذه الحالة يعود للنموذج الذي سيتعلم من هذه النصوص فبعض النماذج بامكانها تحقيق أداء مقبول دون الحاجة للاكتراث بالترتيب.
&lt;h4&gt; طول المتجهات &lt;/h4&gt;
ترميز المستندات باستخدام الفهرس مكلف إذا ما زاد عدد المفردات المميزة في المستند. زيادة هذ الأطوال ينتج عنه تمثيل معقد و متناثر لهذه المتجهات.
&lt;h4&gt; التحيز و فقدان الكلمات &lt;/h4&gt;
النصوص تحمل معان تعبيرية يسهل على الانسان ادراكها من النص كمعرفة لمن يعود إليه الضمير الغائب  أو الضمير المتصل وغيرها من التحديات التي تفقد إدراكها نماذج تعلم الآلة. سرعان ما تنحاز هذه الضمائر لجنس معين في الخطاب إذا ماوجد هذا الانحياز طريقه إلى البيانات التي تم استخدامها لتدريب النموذج. لنأخذ مثالاً لتوضيح الفكرة: 
&lt;img src=&quot;/assets/images/136-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
النموذج كان منحازاً لتضمين (&quot;مسن&quot; أو &quot;قديم&quot;) لكلمة &quot;رجل&quot; وكانت الثانية من التشابه بينما كلمة &quot;ثمين&quot; كانت ضمنياً أقرب لكلمة &quot;رخيص&quot;.
&lt;br /&gt;
نماذج التضمين التي استخدمناها تكون عاجزة تماماً عند وجود كلمة جديدة لم يسبق للنموذج التعرف عليها. النموذج سيلوح بخطأ برمجي في حال كانت الكلمات المدخلة جديدة على قاموس النموذج. 
&lt;br /&gt;&lt;br /&gt;
سنكمل باذن الله مجالات استخدام النصوص في تعلم الآلة في مقالات قادمة. جميع الأكواد المستخدمة في هذه المقالة متوفرة على مستودع البيانات على هذا
‪&lt;a href=&quot;https://github.com/malhamid/Text-Feature-Extraction/blob/master/text-encoding.ipynb&quot;&gt;‬ الرابط‫.‬&lt;/a&gt;
كما يمكن الاطلاع على كيفية تصنيف النصوص حسب المشاعر في مثال تحدثنا عنه سابقاً على هذا
&lt;a href=&quot;https://github.com/malhamid/SentimentAnalysis&quot;&gt; الرابط.&lt;/a&gt;&lt;h2&gt; المراجع &lt;/h2&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nlp.stanford.edu/projects/glove/&quot;&gt;Global Vectors for Word Representation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Mohammed Alhamid</name></author><summary type="html"></summary></entry><entry><title type="html">تعلم الآلة ‫-‬ أساليب أخذ العينات</title><link href="http://localhost:4000/data_sampling/" rel="alternate" type="text/html" title="&lt;div class=&quot;col-md-6 text-right&quot;&gt;تعلم الآلة ‫-‬ أساليب أخذ العينات&lt;/div&gt;" /><published>2020-05-09T00:00:00-04:00</published><updated>2020-05-09T00:00:00-04:00</updated><id>http://localhost:4000/data-sampling</id><content type="html" xml:base="http://localhost:4000/data_sampling/">&lt;p&gt;&lt;img src=&quot;/assets/images/119-icon.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;https://unsplash.com/@impatrickt&quot;&gt;Photo by Luke Chesser on Unsplash&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
لطالما ارتبط مفهوم العينات بالعملية البحثية التي تتطلب اختبار صحة أو قبول فرضيات يتعذر اختبارها على شريحة واسعة أو باستخدام أمثلة غزيرة.  في تعلم الآلة، سرعان ما نقفز للسؤال عن ماهية البيانات المستخدمة وأحجام توفرها. ستسلط هذه المقالة على الحالات التي نلجأ فيها عند بناء نماذج تعلم الآلة للأخذ بالعينات وتدريب النموذج على عينة من البيانات عوضاً عن كاملها. سنتحدث أيضاً عن أكثر الطرق صحةً سواءً لأغراض التدريب أو الاختبار وما يتعلق بذلك من أساليب علمية. 
&lt;br /&gt;&lt;br /&gt;
عندما يطرح موضوع الأخذ بالعينات يتبادر العديد من المهتمين ببناء نماذج تعلم الآلة للتحدث عن توزيع البيانات لمجموعات تختص كل منها لمهمة محددة: التدريب، التحقق من التعلم، أو اختبار النموذج. لا شك أن هذه الخطوات تحتاج لأساليب أخذ العينات لكن السؤال الأهم الذي لا يجب أن نتغافل عنه، ماذا لو كان استخدام كامل البيانات في هذه العملية غير ممكن. أي أن كثافة البيانات الممكن استخدامها محدودة.     أهمية أخذ العينات لا يقل أهمية عن هندسة النموذج، حيث وجود خلل في تمثيل البيانات يهبط بدقة أداء النموذج أو بقدرتها على استيعاب أمثلة جديدة خارج نطاق العينة.  
&lt;br /&gt;&lt;br /&gt;
تعذُر استخدام جميع البيانات في التدريب يأتي في عدة صور، إما لعدم توفر الإمكانيات لمعالجتها أو عدم إمكانية اسكانها في الذاكرة المؤقتة. على سبيل المثال: لنفرض أن تدريب النموذج لتطبيق معين يجب أن يتم في ثوان، وعليه اللجوء لأخذ عينات أمر أساسي ومنه يجب أن نصل لآلية لأخذ أفضل الصور التي تمثل البيانات الحقيقية. نقصد بالصور هنا تلك العينات التي تصور لنا خصائص البيانات الكبيرة بشكل مختزل مع الحفاظ على خصائصها الإحصائية.
&lt;br /&gt;&lt;br /&gt;
&lt;h3&gt; تعذر استيعاب البيانات الكبيرة &lt;/h3&gt;

البيانات تتسم عادة بأحجام مختلفة حسب سياق التطبيق أو النظام الذي يستخلصها من البيئة التشغيلية. وعند رغبتنا في بناء نماذج تعلم الآلة فإن امكانية استيعاب هذه البيانات مبني على توفر بنية تحتية تستطيع استيعاب كمية كبيرة من هذه البيانات. اسكان هذه البيانات في الذاكرة ومعالجتها أمر ليس بالسهولة ووفي الواقع فإن البيئة التشغيلية تحتم علينا التعامل مع عدد محدد من الأحجام.
&lt;br /&gt;&lt;br /&gt;
من الجانب الآخر الوقت المستغرق لبناء النموذج يحتم علينا اللجوء لأخذ عينات أو اجتزاء جزء من البيانات الكلية لغرض التدريب. في كثير من الأحيان يتطلب على مهندسي نماذج تعلم الآلة بناء نموذج لا يستغرق تدريبه إلا دقائق معدودة. هذا السبب يعود لتطلع الشركات لاستمرارية تعلم النماذج و استيعاب حقائق جديدة عوضاً عن بناء نموذج واحد مكلف. على سبيل المثال، توقع المبيعات لا يعتمد على بيانات جمعت في السنوات الماضية فقط بل يعتمد على البيانات المتدفقة بشكل مستمر. وفي سياق آخر من الممكن الاكتفاء بنموذج واحد مكلف كالنماذج اللغوية التي لا تحتاج لإعادة التدريب بشكل مستمر وتكون أساليب أخذ العينات ليس بسبب الحجم فقط ولكن لأسباب أخرى سنذكرها في هذا المقال.

&lt;br /&gt;&lt;br /&gt;
&lt;h3&gt; عدم توازن البيانات &lt;/h3&gt;
&lt;img src=&quot;/assets/images/122-icon.jpg&quot; alt=&quot;&quot; /&gt;

&lt;br /&gt;&lt;br /&gt;
في واقع تعاملنا مع نماذج تعلم الآلة من الطبيعي أن نتوقع وجود خلل في تمثيل البيانات ذلك يعود للطريقة التي جمعت بها. لو أردنا بناء نموذج يتوقع نسبة قبول طالب ما في كلية الطب بناء على أدائه الدراسي فإن المجتمع الذي تمثله البيانات المجمعة يجب أن يكون متوازناً. فلا يمكن دراسة أداء الطلاب دون الطالبات أو أن تمثيل الطلاب يفوق عدد تمثيل الطالبات و العكس صحيح. بالاضافة إلى أهمية الأخذ بعين الاعتبار أخذ عينات من مدراس مختلفة وغيرها. وجود أي خلل في تمثيل هذه البيانات حتماً سيؤثر على أداء النموذج و قدرته على استيعاب حالات جديدة تحمل خصائص احصائية مختلفة عن ما تعلمته الآلة أثناء التدريب.
&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; ما هي الطرق المناسبة؟ &lt;/h1&gt;
&lt;h3&gt; العينات العشوائية &lt;/h3&gt;
العينات العشوائية فعالة غالباً وتعكس الشكل التمثيلي للبيانات الأساسية بشكل جيد وذلك بسبب إعطاء كل عينة نفس احتمالية الفرصة في الاختيار دون أي انحياز أو تدخل في تشكيل توزيعات هذه العينات. نلجأ للعشوائية في جميع الحالات التي لا يتطلب النموذج فيها على أي خصائص معينة في تشكيل البيانات المستهدفة ويترك للعينات أن تترشح بشكل عشوائي. نلجأ لهذا الأسلوب كذلك في الحالات التي يتعذر علينا فهم الخصائص المستهدفة في العينات التي يجب علينا تجميعها لبناء النموذج. العشوائية تضفي فعالية كما ذكرنا بسبب توحيد احتمالية التمثيل لكنها في حد ذاتها ليست مثالية في كل الحالات كما تبينه الصورة التالية.
&lt;img src=&quot;/assets/images/120-icon.jpg&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
النقاط المضاءة باللون الأخضر تعبر عن عينات محددة عشوائيا بينما المضاءة باللون الأحمر تمثل البيانات التي لم تستخدم في تمثيل العينة. المتجه س والمتجه ص يمكن أن يمثل أي بعد تمثله هذه البيانات. كما تبين الصورة، من المحتمل أن نفقد تمثيل أجزاء مهمة من توزيعة البيانات قد تؤثر على أداء النموذج خصوصاً مع صغر حجم العينة.
&lt;br /&gt;&lt;br /&gt;
من الطرق المستخدمة لتطبيق آلية أخذ عينات عشوائية ما يسمى ب (Reservoir Sampling). هذه الخوارزمية العشوائية تمكننا من اختيار نافذة داخل البيانات من توزيعة البيانات الأساسية عن طريق اختيار أرقام عشوائية كما هو موضح في الصورة التالية:
&lt;img src=&quot;/assets/images/125-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;h3&gt; العينات الطبقية &lt;/h3&gt;
من الحلول التي انصح بالاطلاع عليها خصوصاً في تمثيل البيانات لغرض بناء نماذج الآلة أخذ العينات الطبقية. تأخذ العينات الطبقية (Stratified Sampling) قوتها من مفهوم تشكيل مجموعات بيانية ومن ثم أخذ عينات عشوائية من كل مجموعة بشكل متوازن. فهي تتسم بالتصنيف المسبق مع الحفاظ على التحلي بالعشوائية في أخذ العينات من كل مجموعة كما في الصورة التالية.
&lt;img src=&quot;/assets/images/121-icon.jpg&quot; alt=&quot;&quot; /&gt;
&lt;h3&gt; عينات المجاميع العشوائية  &lt;/h3&gt;
طريقة (Cluster Random Sampling) تشبه الطريقة الطبقية بإضافة العشوائية في اختيار المجموعة نفسها ويطلق عليها في بعض الكتب العينات العنقودية.
&lt;br /&gt;
&lt;img src=&quot;/assets/images/123-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;
الطرق الإحصائية تقترح أسلوبين في التعامل مع هذه الطريقة إما أخذ المجموعة كاملة بكل عيناتها أو العودة للاختيار عينات عشوائية من هذه المجموعات. 
&lt;h3&gt; الطريقة الممنهجة &lt;/h3&gt;
هناك طرق لأخذ العينات تعتمد على عملية ممنهجة تعتمد على نظام متسلسل في الاختيار.  لإعطاء مثال لتوضيح الفكرة: عند بناء بيانات لتدريب نموذج لتوقع أسعار الأسهم في سوق التداول، فقد يكون من المهم أخذ قراءة أسعار الشركات عند فتح السوق و عند غلق السوق وأخرى تمثل متوسط سعر المضاربة بين فتح و إغلاق السوق. هذه العملية الممنهجة هي في الحقيقة أخذ عينات من أسعار المضاربة في سوق الأسهم بناء على التسلسل الزمني. 
&lt;br /&gt;
&lt;h3&gt; العينات المبنية على الحصص &lt;/h3&gt;
بعض النماذج يجب أن نعير الاهتمام فيها إلى سياق القرار المتوقع التنبؤ به أو القيم المراد للنموذج أن يتعلمها. على سبيل المثال، هناك نماذج حقيقية انتشر مؤخراً انحيازها لجنس المتقدم للحصول على بطاقة ائتمانية. الشركة اصدرت بطاقات ذات حد ائتماني منخفض لمتقدمة أنثى تحمل نفس العمر و مستوى الدخل لمتقدم آخر رجل. هذا الانجياز يكون مسببه خلل في توازن عناصر مهمة مثل العمر أو الجنس أو المدينة المقيم فيها المتقدم وغيرها. لحل هذه المشكلة، نلجأ لتقسيم البيانات لحصص متسواية من العينات يكون التمثيل فيها متجانساً. مثال آخر، لو أردنا لنموذج أن يتعلم تصنيف رسائل البريد الإلكترونية إلى رسائل مزعجة وغير مزعجة فإن تمثيل العينات يجب أن يكون متجانساً بحيث لا يغلب الغير مزعج منها على الآخر و العكس صحيح.
&lt;br /&gt;&lt;br /&gt;
&lt;h3&gt; إعادة التوازن &lt;/h3&gt;
في مجال تعلم الآلة نتعامل مع اختلال التوازن الذي تمثله العينات بطريقتين: الأولى خفض التمثيل (Undersampling) والأخرى رفع التمثيل (Oversampling) كما في الصورة التالية:
&lt;br /&gt;
&lt;img src=&quot;/assets/images/124-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; توزيع العينات أثناء بناء النموذج &lt;/h1&gt;
كما ذكرت في بداية هذا المقال، الحديث عن أخذ العينات لبيانات التدريب وتوزيعها لمجموعات لكل مرحلة في قناة بناء النموذج هي الحاجة الأكثر شيوعاً لحاجتنا لأخذ العينات. قبل أن نتطرق للتفاصيل يجب أن أوضح أن كل الطرق السابقة تأتي في تمثيل البيانات قبل هذه الخطوة وأن تقسيم البيانات لبيانات للتدريب (Training Set)، أو التحقق من التعلم(Validation Set)، أو اختبار النموذج (Testing Set) هي بعد الوصول لتمثيل بياني مناسب للتعلم الآلي بالإجمال.
&lt;br /&gt;&lt;br /&gt;
يتم تقسيم البيانات لأغراض التدريب لمجموعتين تشكل بيانات التدريب فيها ٨٠٪ من مجمل عدد العينات و يستخدم ٢٠٪ المتبقية لأغراض اختبار أداء النموذج.  ثم يعاد تقسيم بيانات التدريب باستخدام نفس القاعدة (٨٠-٢٠) لنحصل على مجموعتين: مجموعة المدخلات للتدريب ومجموعة التحقق والتي تعتمد عليها الخوارزميات في تتبع مراحل تعلم النموذج و كذلك في ضبط معاملات النموذج. 
&lt;br /&gt;&lt;br /&gt;
الاكتفاء بهذا التقسيم غير كافٍ، ذلك يعود للأسباب التالية: أولاً احتمالية أن توزيع البيانات العشوائي بسبب بمصادفة مكنت النموذج من بذل أداء تنبؤ عالي جداً يختلف عن فيما لو أعيدت خطوة التدريب و الاختبار. و السبب الآخر أن عدد العينات المستخدمة غير كاف لتعلم النموذج. وفي هذه الحالتين نلجأ لما يسمى ب (k‪-‬fold). مفهوم (k-fold) يتيح لنا تقسيم المجاميع إلى عدد (k) بحيث أن كل مجموعة من هذه المجاميع تُستخدم للتحقق و يعاد المتبقي منها للتدريب و تعاد الكرة بمجموعة أخرى للتحقق لا تتقاطع مع سابقتها و يستخدم المتبقي منها في التدريب وهكذا.

&lt;br /&gt;&lt;br /&gt;
وفي الختام أريد أن أنوه أن الطرق الإحصائية تزخر بالعديد من الأساليب العلمية المتبعة لأخذ العينات بطريقة غير عشوائية كالعينات العرضية أو العينات القصدية التي تهتم بشريحة معينة من البيانات و غيرها. لا شك بأهمية هذه الأساليب بحثياً في حالات مختلفة لكن استخدامها محدود في مجال تعلم الآلة نظراً لاننا دائماً ما نبحث عن تمثيل حقيقي للبيانات من خلال أخذ عينات تتسم بالشمولية.
&lt;/div&gt;</content><author><name>Mohammed Alhamid</name></author><summary type="html"></summary></entry><entry><title type="html">فهم الاختلافات بين مكتبتي لغة بايثون NumPy و Numba</title><link href="http://localhost:4000/numpy_vs_numba/" rel="alternate" type="text/html" title="&lt;div class=&quot;col-md-6 text-right&quot;&gt;فهم الاختلافات بين مكتبتي لغة بايثون NumPy و Numba&lt;/div&gt;" /><published>2020-03-27T00:00:00-04:00</published><updated>2020-03-27T00:00:00-04:00</updated><id>http://localhost:4000/ar_numpy_numba</id><content type="html" xml:base="http://localhost:4000/numpy_vs_numba/">&lt;p&gt;&lt;img src=&quot;/assets/images/113-icon.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;a href=&quot;https://unsplash.com/@impatrickt&quot;&gt;Photo by Patrick Tomasso on Unsplash&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
NumPy و Numba هما حزمتان رائعتان متاحتان بلغة بايثون لإجراء عمليات على المصفوفات. كلاهما يعملان بكفاءة على مصفوفات متعددة الأبعاد. في لغة بايثون، تحمل طريقة بناء المتجهات طبيعة ديناميكية. سيؤدي إلحاق قيم جديدة بالمصفوفة إلى زيادة حجم المصفوفة تلقائياً. تعمل مصفوفات NumPy بشكل مختلف حيث تُبنى المصفوفات في أحجام ثابتة. يعني ذلك أن اضافة أو إزالة أي عنصر يقتضي إنشاء مصفوفة جديدة تماماً داخل الذاكرة. في هذه المقالة، نتطلع إلى إيجاد بنية ذات كفاءة تكون فعالة لحل بعض المشاكل البسيطة.
&lt;br /&gt;&lt;br /&gt;
ما هو أساسي عند بدأ النقاش ليس فقط كيفية إنشاء المصفوفة، بل كيفية تطبيق العمليات العلمية المكلفة على هذه المصفوفات، خاصة المصفوفات التي تطلب مسح كافة القيم. الأداء هو الدافع الرئيسي لامتلاك تلك المكتبات عندما نطبق عليها بعض العمليات المكلفة. على سبيل المثال، عندما نقوم بتطوير نماذج تعلم الآلة، خاصة في البيئة التشغيلية، فإننا نقضي قدراً معقولاً من الوقت في تحسين الشفرات التي تنشئ بيانات التدريب باستخدام أي تحويلات مطلوبة أو أي عملية أخرى تتعلق باستخراج وتحويل وتحميل البيانات (ETL). يعد استخدام بعض لغات الآلة البرمجية مثل لغة C أو Fortran أمراً مثالياً، ولكن يتطلب منا إنشاء غلاف &quot;wrapper&quot;  هنا وهناك لإعادة العملية التنفيذية للغة بايثون.
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; بناء المصفوفات في بايثون &lt;/h1&gt;

دعونا نحصل على مثال بسيط: أولاً، سننشئ متجه بسيط بلغة بايثون يحتوي على عشرة ملايين صف. سنتمكن من خلال هذا العدد الكبير ابراز الاختلافات في الأداء بسهولة.
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# We need to import the random package to fillup the array with some random values.import random
array = []
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;

أنا استخدم IPython ؛ إذا كنت تقوم بتشغيل هذه الشفرات على Jupyter Notebook ، فأوصي باستخدام الأمر &quot;السحري&quot; المدمج (time).
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%%time
for i in range(0,10000000):
	val = random.randint(0,1000)
	array.append(val)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; حساب التردد &lt;/h1&gt;


دعونا نبحث في هذه القائمة عن عدد الصفوف التي تحتوي على القيمة 999؟

&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%%time
freq = 0 
for value in array: 
	if value == 999: 
		freq = freq + 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
استغرق تنفيذ الأمر على جهازي الخاص 461 مل ثانية ، ووجدت الدالة 10184 مثيلاً للقيمة 999. والآن دعنا نرى كيفية القيام بنفس المهمة باستخدام مصفوفات NumPy.

&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np

# We use the same list created earlier: 
np_array = np.array(array)
# To get a sense of the size of the bumpy array, simply call up the function 'shape'
print('The size of the numpy array: ', np_array.shape)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
البحث عن عدد الصفوف التي تحتوي على القيمة 999 في مصفوفة NumPy هو سطر واحد فقط من التعليمات 
البرمجية:
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%%time
result = np.where(np_array == 999)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;

بالإضافة إلى كتابة بعض القليل من التعليمات لتنفيذ نفس المهمة، استغرق الأمر 12.6 مل ثانية للقيام بنفس مهمة المصفوفة التقليدية.

يرجى ملاحظة أن آلية الفهرسة لمصفوفة NumPy تشبه أي قائمة تقليدية بلغة بايثون.

الآن سنجعل المثال أكثر إثارة للاهتمام من خلال ادخال بعض العمليات الرياضية على قيم المصفوفة. أولاً، سنقوم ببناء ثلاثة متجهات (X ، Y ، Z) من القائمة الأصلية ومن ثم سنقوم بنفس المهمة 
باستخدام NumPy.
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%%time
def apply_operation_list(array): 
    # We need to build an X vector from the original array
    # The math operations in this function represents some random logic.
    x_array = [] 
    for array_v in array: 
        x_array.append(array_v * 2)
    
    # Building the Y vector
    y_array = []
    for array_v, x_array_v in zip(array, x_array): 
        y_array.append(array_v + x_array_v)
    
    # Building the Z vector
    z_array = []
    for array_v, x_array_v, y_array_v in zip(array, x_array, y_array):
        if x_array_v == 0: 
            z_array.append(0)
        else: 
            z_array.append((array_v - x_array_v ) + y_array_v)
    
    return x_array, y_array, z_array
%%time
x_array, y_array, z_array = apply_operation_list(array)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
استغرق تطبيق العملية على القائمة 3.01 ثانية.
دعونا نعيد نفس الوظيفة باستخدام Numpy:

&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def apply_operation_numpy(array): 
    # We need to build an X vector from the original array
    # The math operations in this function represent some random logic.
    x_array = array * 2
    
    # Building the Y vector
    y_array = array + x_array
    
    # Building the Z vector
    z_array = ( array - x_array ) + y_array
    
    return x_array, y_array, z_array
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;

باستخدام Numpy ، استغرق الأمر 132 مل ثانية فقط.
&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; Numba &lt;/h1&gt;
&lt;img src=&quot;/assets/images/114-icon.png&quot; alt=&quot;&quot; /&gt;

&lt;br /&gt;&lt;br /&gt;
تعمل مكتبة Numba بشكل مثالي مع العمليات البرمجية المكتوبة بلغة بايثون ويمنحك امتياز استخدام مكتباتك الرياضية المفضلة لديك ولكن تم تجميعها وفقاً لتعليمات الآلة الأصلية [2]. يعد استخدام Numba أمراً بسيطاً ولا يتطلب منك تغيير الطريقة التي تكتب بها الدالة:

&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Loading the Numba package
# Jit tells numba the function we want to compile
from numba import jit
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
لاحظ أن كل ما يتعين علينا تغييره مقارنة بالدالة السابقة التي استخدمنا فيها Numpy المحددة أعلاه.
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@jit
def apply_operation_numba(array): 
    # We need to build an X vector from the original array
    # The math operations in this function represents some random logic.
    x_array = array * 2
    
    # Building the Y vector
    y_array = array + x_array
    
    # Building the Z vector
    z_array = ( array - x_array ) + y_array
    
    return x_array, y_array, z_array
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;

باستخدام Numba ، استغرق حساب المتجهات الثلاثة 71.5 مل ثانية فقط.

&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; أيهما نستخدم؟ &lt;/h1&gt;

&lt;em&gt;
&quot;NumPy هي الحزمة الأساسية للحوسبة العلمية مع بايثون. تحتوي بالإضافة إلى أشياء أخرى على كل من: مصفوفات ذات كفاءة متعددة الأبعاد، وظائف (بث) متطورة، وأدوات لدمج أكواد ++C /C و Fortran ، وكذلك الجبر الخطي، وتحويل فورييه ، وقدرات لاستصدار الأرقام العشوائية &quot;[1]
&lt;/em&gt;

&lt;br /&gt;&lt;br /&gt;

NumPy عبارة عن حاوية هائلة لضغط مساحة المتجه الخاصة بك وتوفير مصفوفات أكثر كفاءة. أهم ميزة هي أداء تلك الحاويات عند إجراء أي معالجة لهذه المتجهات.


تم تصميم Numba ، من ناحية أخرى ، لتوفير أكواد بلغة الآلة الأم يعكس وظائف لغة بايثون. يمكن النظر إلى لغة بايثون كغلاف لدوال Numba. من تجربتي ، نستخدم Numba في حالات كانت الوظيفة المراد عملها لا تُدعم من قبل Numpy. أي أن الوظيفة لا تتوفر من هذه المكتبة لمعالجة المتجهات. إذا كانت الوظيفة المخصصة التي تم تنفيذها ليست سريعة بما يكفي في سياقنا ، فيمكن أن تساعدنا Numba في إنشاء هذه الوظيفة داخل مترجم بايثون. هذه هي أيضاً التوصية المتاحة من شرح مكتبة Numba الرسمي.

&lt;br /&gt;&lt;br /&gt;
لا يوضح المثال المقدم في وقت سابق مدى أهمية الفرق؟ هذا صحيح لأننا نبحث فقط عن تكرار قيمة واحدة. دعنا نكرر التجربة عن طريق حساب تكرار جميع القيم المتوفرة في العمود.

&lt;br /&gt;&lt;br /&gt;
في  لغة بايثون ، الطريقة الأكثر فعالية لتجنب ما يسمى بالعقدة البرمجية المتداخلة - ذات التكلفة O ^ 2  - هو استخدام الدالة &quot;العداد&quot; (count). باستخدام سطر واحد فقط من الكود ، يمكننا حساب ترددات العمود كاملاً:

&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%%time
count = {x:x_array.count(x) for x in x_array}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
ومع ذلك ، اعتماداً على قوة المعالجة لديك ، قد تستغرق هذه الوظيفة ساعات لإكمال 10 ملايين سجل. دعنا نرى بعد ذلك ما يمكن أن تقدمه Numpy:

&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%%time
x_elements_np, x_counts_np = np.unique(x_array_np, return_counts=True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
استغرق حساب تردد عمود بطول مليون صف 388 مللي ثانية باستخدام Numpy. نقلة كبيرة في الأداء! لاحظ أن هذه الوظيفة يتم تحسينها عن طريق حساب تردد القيم المميزة فقط. هذا مثال يوضح كيف أن استخدام حلقة متداخلة في بيئة بيانات كبيرة أمر غير واقعي.

&lt;br /&gt;&lt;br /&gt;
حتى وقت قريب ، لم تكن Numba تدعم وظيفة np.unique ، ولكن مع ذلك ، لن تحصل على أي فائدة إذا استخدمت مع return_counts. هذا فقط يظهرأنه في بعض الأحيان يمكن أن يكون Numpy هو الخيار الأفضل عند الاختيار.

&lt;br /&gt;&lt;br /&gt;
وأخيرًا ، يوضح الرسمان التاليان أداء وقت التشغيل باستخدام بنية بيانات مختلفة. يمثل المحور س زيادة تدريجية في حجم البيانات من 10000 صف إلى مليار صف.

&lt;img src=&quot;/assets/images/115-icon.png&quot; alt=&quot;&quot; /&gt;

يوضح الشكل التالي أداء Numby مع مكتبة Numba. لاحظ أن الرقم قد يختلف اعتماداً على حجم البيانات. توضح الأرقام في الرسم البياني متوسط تكرار التجربة لخمس مرات.
&lt;img src=&quot;/assets/images/117-icon.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; المزيد من الأمثلة &lt;/h1&gt;
&lt;h2&gt; تحليل القيم المنفردة (SVD) &lt;/h2&gt;

مثال التكرار هو مجرد تطبيق واحد قد لا يكون كافيا لرسم انطباع شامل ، لذلك دعونا نختار SVD كمثال آخر. SVD هي خوارزمية تعلم غير موجَّه. تسمح الخوارزمية بتفكيك مصفوفة كبيرة إلى منتج من مصفوفات متعددة أصغر في الحجم. SVD لديه العديد من التطبيقات في تعلم الآلة ويستخدم لتقليل الأبعاد. &lt;a href=&quot;https://towardsdatascience.com/svd-8c2f72e264f/&quot;&gt;هنا مقال لقراءة المزيد عن هذه الخوارزمية.&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;
يستخدم المثال المكتوب أدناه بعدين اثنين (أعمدة) فقط بنفس عدد الصفوف كما في المثال السابق.

&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from scipy.linalg import svd
# We will consider in this example only two dimensions. 
# m x 2 
# U: m x r 
# s: Diagonal matrix r x r
# VT: n x r
U, s, VT = svd(array_np[:, 0:2])
Sigma = np.zeros((array_np.shape[0], 2))
Sigma[:2, :2] = np.diag(s)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
إذا حاولت تشغيل الكود ، فربما تحصل على خطأ مشابه للرسالة التالية: “ValueError: Too large work array required — computation cannot be performed with standard 32-bit LAPACK.”. وذلك لأن التنفيذ الداخلي لـ lapack-lite يستخدم متغيرات من نوع int للفهرس. مع حجم كبير مثل المجموعة المستخدمة ، سيؤدي ذلك بالتأكيد إلى تجاوز الحد التي تستطيع فهرسته. علينا إما تقليل حجم المتجه أو استخدام خوارزمية بديلة. إذا ما حاولنا استخدام وظيفة SVD مع مكتبة Numba ، فلن نحصل على أي مزايا ملحوظة وذلك لان الدالة تستدعي وظيفة LAPACK SVD.

&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; ضرب المصفوفات &lt;/h1&gt;

ضرب المصفوفات هو مثال آخر يوضح كيف يمكن أن يكون Numba مفيدة لزيادة وقت المعالجة. حتى بدون Cuda ، يمكننا تحقيق أداء أفضل. دعونا نأخذ المثال خطوة بخطوة. كما فعلنا من قبل ، سننفذ وظيفة أولاً باستخدام &quot;قائمة&quot; بايثون.

&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def matrix_multiplication(A,B):
    row, col_A = A.shape
    col_B = B.shape[1]
    result = np.zeros((row,col_B))
    for i in range(0,row):
        for j in range(0,col_B):
            for k in range(0,col_A):
                result[i,j] += A[i,k]*B[k,j] 
    return result
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
لمعالجة 10 ملايين صف، تكون &quot;القائمة&quot; سريعة جداً في معالجة ضرب المصفوفات. وقت التشغيل هو 1 دقيقة و 7 ثوان فقط. باستخدام Numpy ، استغرق الأمر 95 ثانية للقيام بنفس المهمة.
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def matrix_multiplication_numpy(A,B):
    result = np.dot(A,B)
    return result

%%time
result = matrix_multiplication_numpy(array_np, array_np)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
الآن بعد استبدال Numby بـ Numba ، قمنا بتقليل عمليات الضرب المكلفة من خلال وظيفة بسيطة أدت إلى 68 ثانية فقط أي تقليل الوقت بنسبة 28٪.
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@jit
def matrix_multiplication_numba(A, B, result):
    for i in range(result.shape[0]):
        for j in range(result.shape[1]):
            tmp = 0.
            for k in range(A.shape[1]):
                tmp += A[i, k] * B[k, j]
            result[i, j] = tmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div style=&quot;direction: rtl; text-align: right;&quot;&gt;
توضح الشكل البياني التالي أداء ضرب المصفوفة باستخدام قائمة Python ، مع Numpy ، وباستخدام مكتبة Numpy.


&lt;img src=&quot;/assets/images/116-icon.png&quot; alt=&quot;&quot; /&gt;

تم تشغيل الأمثلة المقدمة في هذه المدونة على جهاز MacBook Pro مقاس 15 بوصة 2018 وحجم الذاكرة 16 جيجابايت واستخدام توزيعة أناكوندا. يمكن العثور على التعليمات البرمجية المستخدمة في هذه الأمثلة في مستودع &lt;a href=&quot;https://github.com/malhamid/Python-useful-tools/blob/master/NumPy_Numba_comparisons.ipynb
&quot;&gt; Github&lt;/a&gt;
 الخاص بي. يمكن تحسين الأداء باستخدام بيئة GPU ، والتي لم يتم أخذها في الاعتبار في هذه المقارنة.

&lt;br /&gt;&lt;br /&gt;
&lt;h1&gt; المراجع &lt;/h1&gt;
&lt;/div&gt;
&lt;p&gt;[1] Official NumPy website, available online at https://numpy.org
[2] Official Numba website, available online at http://numba.pydata.org&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><summary type="html"></summary></entry><entry><title type="html">ترميز النصوص: مراجعة</title><link href="http://localhost:4000/ar_posts/ar_encoding/" rel="alternate" type="text/html" title="ترميز النصوص: مراجعة" /><published>2019-12-07T00:00:00-05:00</published><updated>2019-12-07T00:00:00-05:00</updated><id>http://localhost:4000/ar_posts/ar_encoding</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_encoding/">&lt;p&gt;&lt;img src=&quot;https://i0.wp.com/www.nmthgiat.com/wp-content/uploads/2020/01/white-printing-paper-with-numbers.jpg?zoom=2&amp;amp;resize=768%2C399&amp;amp;ssl=1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;نشر في موقع نمذجيات - ٢٧ يناير ٢٠٢٠ م&lt;/p&gt;

&lt;p&gt;العامل الرئيس لتنفيذ أي عملية لاستخراج النص، مثل اكتشاف الموضوع أو تحليل المشاعر، هو تحويل الكلمات إلى أرقام، وتحويل سلسلة الكلمات إلى تسلسل رقمي. بمجرد حصولنا على الأرقام، نعود إلى لعبة تحليل البيانات المعروفة، حيث يمكن أن تساعدنا خوارزميات تعلم الآلة في التصنيف والتجميع.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.nmthgiat.com/ترميز-النصوص-مراجعة/&quot;&gt;لتكملة المقال الضغط على هذا الرابط.&lt;/a&gt;&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="تعلم-الآلة" /><category term="الترميز-في-تعلم-الآلة" /><summary type="html"></summary></entry><entry><title type="html">الكتب، الدورات، وقواعد البيانات التي يجب على كل عالم بيانات معرفتها</title><link href="http://localhost:4000/ar_posts/ar_ml_resources/" rel="alternate" type="text/html" title="الكتب، الدورات، وقواعد البيانات التي يجب على كل عالم بيانات معرفتها" /><published>2019-12-07T00:00:00-05:00</published><updated>2019-12-07T00:00:00-05:00</updated><id>http://localhost:4000/ar_posts/ar_ml_resources</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_ml_resources/">&lt;p&gt;&lt;img src=&quot;https://i0.wp.com/miro.medium.com/max/1514/1*kzdg0w1TOhqAoxpLoWFVNA.png?zoom=2&amp;amp;resize=708%2C396&amp;amp;ssl=1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;نشر في موقع نمذجيات - ٧ ديسمبر 2019م&lt;/p&gt;

&lt;p&gt;بادئ ذي بدء، أنت على الطريق الصحيح. يعد العمل على تعلم الآلة (Machine Learning) من أجل بناء معرفتك في مجال الذكاء الاصطناعي خياراً مميزاً. تحرز تقنيات الذكاء الاصطناعي تقدماً هائلاً ليس فقط في تطوير البرمجيات بل كل جانب من جوانب حياتنا 
اليومية.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.nmthgiat.com/الكتب،-الدورات،-وقواعد-البيانات-التي/&quot;&gt;لتكملة المقال الضغط على هذا الرابط.&lt;/a&gt;&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="كتب-في-تعلم-الآلة" /><category term="مراجع-في-تعلم-الآلة" /><summary type="html"></summary></entry><entry><title type="html">أهم عشرة أخطاء إحصائية يرتكبها علماء البيانات</title><link href="http://localhost:4000/ar_posts/ar_ml_mistakes/" rel="alternate" type="text/html" title="أهم عشرة أخطاء إحصائية يرتكبها علماء البيانات" /><published>2019-12-07T00:00:00-05:00</published><updated>2019-12-07T00:00:00-05:00</updated><id>http://localhost:4000/ar_posts/ar_ml_mistakes</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_ml_mistakes/">&lt;p&gt;&lt;img src=&quot;https://i0.wp.com/www.nmthgiat.com/wp-content/uploads/2020/02/mitsakes.jpg?zoom=2&amp;amp;resize=768%2C295&amp;amp;ssl=1&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;نشر في موقع نمذجيات - ١ فبراير ٢٠٢٠ م&lt;/p&gt;

&lt;p&gt;عالم البيانات هو “شخص أفضل في الإحصاء من أي مهندس برمجيات وأفضل في هندسة البرمجيات من أي إحصائي”. في مقالة سابقة: أهم عشرة أخطاء برمجية قام بها علماء البيانات، ناقشنا كيف يمكن للإحصائيين أن يصبحوا مُبرمجين بشكل أفضل. نناقش هنا كيف يمكن للمبرمجين أن يكونوا إحصائيين بشكل أفضل.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.nmthgiat.com/أهم-عشرة-أخطاء-إحصائية-يرتكبها-علماء-ا/&quot;&gt;لتكملة المقال الضغط على هذا الرابط.&lt;/a&gt;&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="تعلم-الآلة" /><category term="أخطاء-في-تعلم-الآلة" /><summary type="html"></summary></entry><entry><title type="html">القوة الدافعة للاستثمار في المعلوماتية</title><link href="http://localhost:4000/ar_posts/ar_techinvest/" rel="alternate" type="text/html" title="القوة الدافعة للاستثمار في المعلوماتية" /><published>2016-12-21T00:00:00-05:00</published><updated>2016-12-21T00:00:00-05:00</updated><id>http://localhost:4000/ar_posts/ar_techinvest</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_techinvest/">&lt;figure class=&quot;image&quot;&gt;
    &lt;a href=&quot;/assets/images//assets/images/invest-icon.jpg&quot;&gt;&lt;img src=&quot;/assets/images/invest-icon.jpg&quot; /&gt;&lt;/a&gt;
    

&lt;small&gt;Photo by Austin Distel on Unsplash.&lt;/small&gt;
&lt;/figure&gt;

&lt;p&gt;نشر في جريدة الرياض - الاثنين 25 صفر 1438 هـ - 21 ديسمبر 2016م - العدد 1550169 , صفحة رقم ( 30 )&lt;/p&gt;

&lt;p&gt;العالم اليوم يتسارع في التغير اقتصادياً. العديد من الدول النامية غدت تنصرف عن الاعتماد على الثروات الطبيعية متجهة إلى الصناعات المتخصصة معتمدة في ذلك على الخبرات المحلية المدربة. إن برميل النفط الذي يساوي اثنين وأربعين غالوناً على المقياس الأميركي من النفط يلعب دوراً أساسياً في قوة الاقتصاد العالمي لمعظم الدول. فمع الانخفاض الحاد في أسعار النفط اليوم ومقاربته لحدود الثلاثين دولاراً، فقد أصبح حتمياً على معظم الدول الترشيد في وسائل إنفاق الدخل الناتج عن هذه الثروة الطبيعية. وتختلف اليوم وسائل وقنوات الصرف لمعظم الشعوب فيما يتلقونه من دخلهم المحلي الاجمالي على حاجاتهم الخاصة.&lt;/p&gt;

&lt;p&gt;لقد أصبح شغف العديد من المجتمعات حول العالم يزداد تعلقاً بالتقنية وملاحقة ما هو جديد في عالمها. لعل آخر الأخبار التي نتداولها اليوم تتعلق بأحد الهواتف الأميركية المحمولة الذي صدر مؤخراً في نسخته السابعة. نلحظ جميعاً دون أدنى شك ما حققته تلك الشركة من نجاحات في أرقام المبيعات عوضاً عن التقدم التقني الملموس الذي تحققه بتفوق من نسخة إلى أخرى رغم تكلفته العالية وانعزال أسعاره الكامل عما يدور في فضاء الاقتصاد من ذبذبات أثرت كثيراً على العديد من الصناعات وخاصة التي تستخدم المواد النفطية منها.&lt;/p&gt;

&lt;p&gt;إن الاستثمار في التطبيقات الحاسوبية والبيانات الرقمية لم يعد اليوم خياراً مطلقاً. التقارير الاقتصادية تؤكد بشكل مستمر ارتفاع الطلب العالمي على الأجهزة الالكترونية بشكل عام، بالإضافة إلى وجود عدد من الشركات ذات رؤوس الأموال الضخمة لا تقدم أو تبادل منتجات ملموسة سوى إمبراطورية من التطبيقات والبيانات المتنقلة بين القارات. قد يتوارد إلى ذهن القارئ الكريم أن الصناعات ومنها البرمجية تحتاج إلى بيئة مناسبة منافسة مدعومة من قوى عاملة ذات كفاءة تقنية عالية قد لا تتوفر في معظم الدول النامية. هذا وإن كان ذلك صحيحاً في مجمله العام، إلا أنه يوجد من يخالف ذلك المنظور.&lt;/p&gt;

&lt;p&gt;الأرقام اليوم تصنف المحتوى العربي على أنه يحتل المرتبة الثامنة عالمياً وإننا وإن كنا لا ننتج تقنياً بشكل مباشر إلا أن العالم اليوم يستثمر في الاستخدام الذي نشاركه مع العالم. فعلى سبيل المثال، إحدى شركات التسجيل المرئي الشهيرة والتي يتداول مقاطع الفيديو فيها جيل الشباب اليوم في بلادنا، استثمرت ملايين الدولارات عبر الشركاء المحليين في الخليج العربي لدعم ما يحققونه من إيرادات ضخمة حصيلة الإعلان ومتابعة المستخدمين.&lt;/p&gt;

&lt;p&gt;إن الرسم المذكور للوضع ليس من منظور اقتصادي بل من منظور صناعي للتقنية. تستطيع شركات التقنية دعم الاقتصاد الأميركي بإيرادات ضخمة في حال صعود أسعار النفط لأنها تزيد من قدرتنا الشرائية كمستهلكين. لذلك هذا الجهاز المحمول الصغير له تأثير اقتصادي فضلاً عن التأثير الثقافي لما يحتويه من منصات تجارية وثقافية عبر البرامج التي يحملها.&lt;/p&gt;

&lt;p&gt;إن مستقبل أعمالنا واقتصادنا لابد أن يدور حول عالم الإنترنت الذي غير نمط الأعمال والإنتاج والاستهلاك حتى الوصول إلى الحكومة الرقمية والأعمال الإلكترونية. إن التقنية التي نملكها اليوم تمهد لنا مستقبلاً مليئاً بالروبوتات الذكية والطباعة ثلاثية الأبعاد وصولاً للسيارات ذاتية القيادة. لذلك، لنتصور ولو للحظة كم سنتكلف من مدخراتنا الخاصة في سبيل حصولنا على ذلك الجهاز الخليوي في المستقبل.&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="الاستثمار-في-المعلوماتية" /><category term="الاستثمار-في-البيانات" /><summary type="html"></summary></entry><entry><title type="html">رؤية المملكة والاستثمار في البيانات</title><link href="http://localhost:4000/ar_posts/ar_techvision/" rel="alternate" type="text/html" title="رؤية المملكة والاستثمار في البيانات" /><published>2016-06-18T00:00:00-04:00</published><updated>2016-06-18T00:00:00-04:00</updated><id>http://localhost:4000/ar_posts/ar_techvision</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_techvision/">&lt;figure class=&quot;image&quot;&gt;
    &lt;a href=&quot;/assets/images//assets/images/invest-tech-icon.jpg&quot;&gt;&lt;img src=&quot;/assets/images/invest-tech-icon.jpg&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;Photo by NASA on Unsplash&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;السبت 13 رمضان 1437 هـ- 18 يونيو 2016م - العدد 1512314&lt;/p&gt;

&lt;p&gt;سهلت التقنية التي نمتلكها اليوم في جمع ثروة كبيرة من البيانات التي تتفاقم قيمتها وأهميتها يوماً بعد يوم. الكثير من الأشياء التي طرأت مؤخراً في مجال البرمجيات ووسائل التواصل الاجتماعي غيرت الكثير من المفاهيم الهندسية للأنظمة وطرق التعامل مع البيانات، حتى غيرت أيضاً منابعها واستخلصت من خلالها على معلومات ذات قيمة. العالم اليوم أصبح يؤمن أكثر فأكثر بمفاهيم المدن الذكية وتوفير الطاقة وتحويل المنازل إلى منازل تفاعيلة بالإضافة إلى استخدام إنترنت الأشياء. أي أن جميع ما حولنا اليوم يتصل بالشبكة العنكبوتية ويساهم في إنتاج بعض البيانات بشكل مباشر أوغيره.&lt;/p&gt;

&lt;p&gt;البيانات الضخمة أو ما يعرف ب (Big Data) بدأت تستجذب الباحثين والمهتمين في السنوات القليلة الماضية إلا أن سنة 2013 م امتازت بدخول الشركات التجارية الضخمة للاستثمار في هذا المجال. العامل الرئيسي للاستثمار في هذه البيانات هو عامل “تحليل” هذه البيانات. قد يتوارد لك أيها القارئ الكريم أن عملية تحليل البيانات ليس بالأمر الصعب مع وجود التقنية التي وصلنا إليها اليوم، ولكن الصعوبة تكمن في: تحديد مصدر وحجم البيانات الملائم، الهدف المراد الوصول إليه ، تحديد الأسئلة المراد الوصول لإجابات عليها. وعلى ضوء ما سبق شهد مجال تعدين وتحليل و مراقبة البيانات توسعاً غير مسبوق حيث سجل نمواً بما يقارب 65% منذ العام 2013 م.&lt;/p&gt;

&lt;p&gt;لتوضيح أهمية البيانات بشكل أكبر، إليكم بعض هذه الأمثلة. في مجال شركات الطيران، ساعد تحليل البيانات لكثير من شركات الطيران الأميركية على تحسين خدمات العملاء من خلال تحليل البيانات الصوتية المسجلة عند التحدث لخط خدمة العملاء الهاتفي وكذلك سلوك المستخدمين عبر مواقع الحجز ووسائل التواصل الاجتماعي في إعادة صياغة الكثير من العروض السياحية. كذلك من خلال تسجيل معلومات الإقلاع والهبوط وتتبع الحقائب الإلكتروني، أصبح من السهل تتبع أهم النقاط المسببة لتأخر الرحلات أو ضياع الحقائب ومعالجتها بفعالية أكبر.&lt;/p&gt;

&lt;p&gt;في قطاع توزيع البريد، أدى تحليل العديد من البيانات لإحدى شركات توزيع الطرود البريدية في الولايات المتحدة لتوفير ما يقارب عن 37 مليار دولار من خلال توفير بعض خطوط التوصيل بالمركبات والطائرات. هذا التخفيض في تكلفة النقل سببه تسجيل جميع الرحلات، الوقت الذي يستقطعه الموظف لتوزيع الطرود البريدية، تتبع مسار المركبة على الخريطة ومعرفة عدد الأميال، وكذلك تسجيل التكلفة اليومية من الوقود من إعادة جدولة خطوط التوصيل وتوزيعها على المستفيدين.&lt;/p&gt;

&lt;p&gt;المجال الصحي من المجالات المهمة التي يتوقع لها نجاحاً باهراً في حين استغلت تحليل بيانات المرضى ومؤشرات استهلاك الأدوية بشكل فعال. الكثير من المؤشرات يمكن قراءتها في قياس فاعلية الخطة العلاجية وكذلك رصد الأعراض الجانبية. ولتسليط الضوء على ما يمكن أن تقدمه البيانات، أقدمت إحدى شركات التأمين الطبي لاستخدام بيانات تسعة ملايين مريض لتكتشف وجود ترابط بين تناول دواء معين وزيادة نسبة التجلط في الدم. ولذلك المسؤولية اليوم ليس فقط على المستشفيات بالمملكة لمشاركة بياناتها الصحية بل تشاركها شركات التأمين الطبية في مسؤولية دراسة هذه البيانات واستخلاص مؤشرات تساهم في دراسة الوضع الصحي للسكان بالمملكة وتتبع الأنماط الصحية التي يتعرض لها سكان الأحياء، المدن، وصولاً للمناطق.&lt;/p&gt;

&lt;p&gt;في مجال المال والاستثمار، استطاعت إحدى الشركات المالية الاسترالية من بناء منصة معقدة لتحليل البيانات الضخمة من تحديد العديد من المتغيرات التي تمكن الشركة من تحديد المخاطر الاستثمارية حتى استطاعت عبر هذا التحليل من التنبؤ ب 25% من الشركات التي سجلت خسائر في مؤشراتها المالية.&lt;/p&gt;

&lt;p&gt;إن رؤية المملكة 2030 التي شملت في أكثر من نص على أهمية توسيع نطاق الخدمات الإلكترونية، شددت في نفس تلك النصوص على أهمية استحداث منصات للبيانات ذات صفة مشاركة لتعزيز حوكمة العمل الحكومي بما يضمن استيعاباً أكبر عند اتخاذ القرارات.&lt;/p&gt;

&lt;p&gt;أستاذ هندسة برمجيات&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="رؤية-المملكة" /><category term="الاستثمار-في-البيانات" /><summary type="html"></summary></entry><entry><title type="html">الأوراق المالية الإلكترونية</title><link href="http://localhost:4000/ar_posts/ar_emoney/" rel="alternate" type="text/html" title="الأوراق المالية الإلكترونية" /><published>2016-02-01T00:00:00-05:00</published><updated>2016-02-01T00:00:00-05:00</updated><id>http://localhost:4000/ar_posts/ar_emoney</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_emoney/">&lt;figure class=&quot;image&quot;&gt;
    &lt;a href=&quot;/assets/images//assets/images/100-icon.jpg&quot;&gt;&lt;img src=&quot;/assets/images/100-icon.jpg&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;Photo by Austin Distel on Unsplash.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;الأربعاء 1 جمادى الأولى 1437 هـ - 10 فبراير 2016م - العدد 17397 , صفحة رقم ( 22 )&lt;/p&gt;

&lt;p&gt;يعتمد البشر على الأوراق النقدية في معاملاتهم التجارية، فقد كان الصينيون أول من ابتكر التعامل بالورق النقدي بين عامي 618 و900 للميلاد. وفي القرن السابع عشر، بدأ الأوروبيون بتبادل الأوراق النقدية مقابل ما يبتاعونه من سلع. ورغم أن بين الفترة التي ابتكر فيها الصينيون الورق النقدي و انتشاره حول العالم، عانى الصينيون أنفسهم أزمات اقتصادية تتعلق بالتضخم الاقتصادي نتيجة التوسع الشديد في طباعة الورق. وفي العام 1690 م طبعت أول ورقة نقدية في الولايات المتحدة لتغطية تكاليف حرب الملك وليام بين الإنجليز والفرنسيين والتي اندلعت في الشمال الشرقي للولايات المتحدة. كان الغرض الأساسي من تلك الأوراق النقدية أن تقدم للجنود كوثيقة يمكن استبدالها لاحقاً بما يعادلها من الذهب أو الفضة. وفي العام 1862 للميلاد، انطلقت العملة الورقية الرسمية للحكومة الأميركية والسماح باستخدامها في التعاملات التجارية. وبدأت مملكتنا الحبيبة بطباعة أول عملة نقد سعودي لغرض استخدامها كايصالات تقدم للحجاج عوضاً عن الريال الفضي السعودي حوالي العام 1953 للميلاد.&lt;/p&gt;

&lt;p&gt;مع التطور الاقتصادي والتجاري في مختلف أجزاء العالم بين الأعوام 1880 و1890 للميلاد، بدأت بعض المصارف وكذلك المتاجر الكبيرة باستخدام الأوراق الاعتمادية التي تعطي لصاحبها الحق في تعويض هذه الأوراق بسلع كالملابس أو حتى استبدالها بالورق النقدي. وفي العام 1958 للميلاد، أطلقت شركة أميركان اكسبرس أول بطاقة ائتمانية من البلاستيك والتي سرعان ما انتشرت لاحقاً خارج الولايات المتحدة وخصوصاً في المملكة المتحدة.&lt;/p&gt;

&lt;p&gt;بعد الوقوف على المشهد التاريخي للتعاملات النقدية، نود أن نستقرئ ما قد تؤول إليه المعاملات المالية في المستقبل القريب واضعين في عين الاعتبار التحول الاقتصادي الذي يشهده العالم إلى ذاك الاقتصاد الرقمي الذي نعيشه اليوم. فقد أصبحت التعاملات المالية اليوم يُعبر عنها بتغيرات رقمية في قواعد بياناتها البنكية. انفاقُنا اليومي، الحوالات المالية وجميع مدخراتنا الشخصية عبارة عن أرقام تُتداول عبر شبكة الإنترنت.&lt;/p&gt;

&lt;p&gt;العديد من المحللين الاقتصاديين يستقرئون الاستغناء الكامل عن النقد قريباً وربما قريباً جداً. على النقيض، يختلف البعض الآخر في أننا قد نستغني تدريجياً عن النقد ولكن ليس من الأفضل الاستغناء الكلي عنه. من يؤيد المجموعة الأولى في التحول للعملة الإلكترونية يعللون موقفهم بفوائد تعزيز الجانب الأمني. فأغلب الأنشطة غير الشرعية من غسيل الأموال ، بيع المخدرات، الرشاوى والتحايل على الضرائب الحكومية أساس التعامل فيها على النقد والنقد فقط لصعوبة تتبع مصدره. ففي الولايات المتحدة الأميركية وحدها، قدر أحد الاقتصاديين بأن ما بين 18 إلى 20 في المئة من الإيرادات الشخصية لم تخضع للضريبة الحكومية. ومن المهم أيضاً أن نعلم أن طباعة ومراقبة و صيانة العملة الورقية مكلفة في بعض الدول حتى أنها قد وصلت إلى ما يقارب 1 في المئة من الدخل القومي لأحداها. أما من يعارض الاستغناء الكلي عن النقد يبررون موقفهم بأمثلة من الصعب التعامل فيها بالعملة الالكترونية كشراء الخضار، الأطعمة الخفيفة، أو شراء علبة من المياة في طريق عودتهم للمنزل و التي عادة يُتبادل فيها بمبالغ مالية بسيط جداً.&lt;/p&gt;

&lt;p&gt;بعيداً عن الاقتصاديين، يرى خبراء التقنية في الهواتف المحمولة وسيلة التعامل المالي في المستقبل عبر تمرير الهواتف على أجهزة استشعار كهرومغناطيسية يمكن استخدامها في سداد العمليات المالية ذات القيمة البسيطة مع الإبقاء على البطاقات البنكية في العمليات ذات القيمة المالية المرتفعة. مما قد يعني لنا بأن بعض شركات الاتصالات قد تتحول تدريجياً إلى بناء شراكات يمكنها من لعب دور المصارف المالية لتداول الأموال الإلكترونية. ففي كندا اليوم - على سبيل المثال – غالبية البنوك المالية تسمح لعملائها بعمل حوالة مالية باستخدام البريد الإلكتروني للمستفيد فقط وهي تجربة ساهمت بشكل كبير في دعم التجارة الإلكترونية وإضافة المزيد من التسهيلات للعاملين من منازلهم.&lt;/p&gt;

&lt;p&gt;*أستاذ هندسة البرمجيات المساعد بجامعة الملك سعود&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="الأوراق-المالية" /><category term="العملة-الرقمية" /><summary type="html"></summary></entry><entry><title type="html">التحول لاقتصاد المعرفة</title><link href="http://localhost:4000/ar_posts/ar_ecoknow/" rel="alternate" type="text/html" title="التحول لاقتصاد المعرفة" /><published>2016-01-16T00:00:00-05:00</published><updated>2016-01-16T00:00:00-05:00</updated><id>http://localhost:4000/ar_posts/ar_ecoknow</id><content type="html" xml:base="http://localhost:4000/ar_posts/ar_ecoknow/">&lt;figure class=&quot;image&quot;&gt;
    &lt;a href=&quot;/assets/images//assets/images/101-icon.jpg&quot;&gt;&lt;img src=&quot;/assets/images/101-icon.jpg&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;p&gt;&lt;small&gt;Photo by Austin Distel on Unsplash.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;السبت 6 ربيع الأخر 1437 هـ - 16 يناير 2016م - العدد 17372, صفحة رقم ( 35 )&lt;/p&gt;

&lt;p&gt;يشهد عهد خادم الحرمين الملك سلمان بن عبدالعزيز -حفظه الله- عزماً قوياً على المضي في تنوع مصادر الدخل والاستثمار في بناء اقتصاد المعرفة لخلق المزيد من فرص العمل والاستمرار في دعم الازدهار والإصلاح الاقتصادي، هذا العزم يواكب التحول الاقتصادي الذي يعيشه العالم في الاستثمار في التقنية وبناء شبكات اتصال لتنقل الحركة الاقتصادية من التقليدية إلى عالم المال والأعمال عبر شبكة الإنترنت. التعدين والتنقيب اليوم لم يعد حكراً على الموارد الطبيعية كالذهب وغيره من المعادن، بل التنقيب اليوم في البيانات وزراعة تطبيقات رقمية تساهم في تسويق تلك المعلومات المستخلصة من حركة البيانات حول العالم، كما أن المصانع ليست المنبع الوحيد للصناعة بل معامل البحث والتطوير سواء في الجامعات أو الشركات التي أصبحت المصدر الملهم لصناعة المستقبل.&lt;/p&gt;

&lt;p&gt;على سبيل المثال تبلغ اليوم القيمة السوقية لشركة “فيس بوك” عملاق الشبكات الاجتماعية ما يقارب 200 مليار دولار، كما بلغ الدخل الإجمالي للشركة لعام 2014 ما يقارب 12.47 مليار دولار. هذا يعني أن 11,996 إجمالي عدد موظفي شركة “فيس بوك” المعلن استطاعوا صناعة استثمارات عبر شبكات التواصل الاجتماعية فاقت إيراداتها ميزانية دول عديدة كلبنان، قبرص، السودان، سورية، اليمن، بنغلاديش، وغيرها من الدول.&lt;/p&gt;

&lt;p&gt;هذه ليست أول مرة يُلحظ فيها أن إيرادات الشركات العملاقة يفوق إيرادات دول كبيرة، فعلى سبيل المثال إحدى شركات التجزئة الكبرى في الولايات المتحدة الأمريكية يفوق إجمالي مبيعاتها الدخل القومي للنرويج إحدى الدول الأوروبية ذات المرتبة المتقدمة في اقتصادات العالم، لكن المختلف هذه المرة هي نوعية المنتجات والتي تعتمد كلياً على المعلوماتية، بما فيها الدخل الناتج عن الدعاية عبر الإنترنت.&lt;/p&gt;

&lt;p&gt;إدراكاً لما سبق فقد عمدت المملكة مؤخراً وبشكل متسارع إلى تقديم تسهيلات للشركات الأجنبية لتصنيع منتجاتها داخل المملكة نقلاً للتقنية وخلقاً لمزيد من الفرص للشباب السعودي. كما دعمت قطاع المال بمدينة الملك عبدالله المالية وبناء مجتمع متطور ومبتكر متمثلاً في مشروع مجمع تقنية المعلومات والاتصالات، ويُعول على رجال الأعمال المزيد من الالتفات الجاد للاستثمار في المعلوماتية وصناعة التقنية لبناء شركات تساهم في بناء البنية الرقمية للمملكة والتكيف مع فرص الاستثمار الجديدة؛ وأخص بالذكر استنساخ تجربة وادي السيليكون بالولايات المتحدة في دعم الشركات الناشئة على شبكة الإنترنت والشركات الصغيرة ذات الحلول التقنية المبتكرة.&lt;/p&gt;

&lt;p&gt;أستاذ هندسة البرمجيات المساعد
بجامعة الملك سعود&lt;/p&gt;</content><author><name>Mohammed Alhamid</name></author><category term="اقتصاد-المعرفة" /><category term="التحول-الرقمي" /><summary type="html"></summary></entry></feed>